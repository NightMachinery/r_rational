#+TITLE: Has anyone here read Peter Watts' Blindsight?

* Has anyone here read Peter Watts' Blindsight?
:PROPERTIES:
:Author: Wizard-of-Woah
:Score: 76
:DateUnix: 1593080024.0
:DateShort: 2020-Jun-25
:END:
/Blindsight/ is a hard sci fi cosmic horror flavoured first contact story by author and marine biologist Peter Watts, about a crew of posthumans (along with their pet baseline interpretor) encountering a bizarre alien construct/organism beyond the edge of the Oort Cloud. It's probably most famous for its unique, wizard-killing take on vampires, positing them as a prehistoric subspecies of obligatory cannibals with savant level intelligence, but the core of the story is much more about the relationship between sapience and intelligence, and whether you need the first to have the other. It feels... relevant to this community's interest.


** I have seen it recommended here many times when people ask for novels, along with /Echopraxia/.

General review from what I remember: I really enjoyed his take on vampires, and felt that the story neatly slid in to the cosmic horror genre without actually leaving sci-fi, which is a rare but laudable occurrence. The aliens are well formulated and the suspense is executed well in general, though I didn't like the AI twist near the end. At the conclusion of reading it I felt like the book had effectively argued for the meaningfulness of the core self-awareness =//= intelligence premise.

On the other hand, the characters and much of the social speculation left much less of an impact, even considering the interesting ideas that some of them were based around. Not they they were incompetently executed, just that they didn't really compare to the other stuff in terms of being strikingly memorable.
:PROPERTIES:
:Author: DeepTundra
:Score: 44
:DateUnix: 1593081495.0
:DateShort: 2020-Jun-25
:END:

*** Very much so. It was an interesting exercise, but I left with no real reason to care about the characters or ideas.
:PROPERTIES:
:Author: Zarohk
:Score: 8
:DateUnix: 1593096569.0
:DateShort: 2020-Jun-25
:END:

**** Yes, I agree. The narrative, while true to the protagonist's unusual thought processes, also makes the book harder to follow.

It was an interesting book with some cool ideas, but it wasn't a book I particularly /enjoyed/ reading.

(Aside: my use of this username predates the book's publication by a few years, in case anyone is confused by my lukewarm opinion of the title.)
:PROPERTIES:
:Author: blindsight
:Score: 14
:DateUnix: 1593117720.0
:DateShort: 2020-Jun-26
:END:


*** Have you read his Behemoth? I thought it did a much better job with characters, but it seems much less well-known, perhaps because of the weird publication model.
:PROPERTIES:
:Author: NoYouTryAnother
:Score: 3
:DateUnix: 1593139666.0
:DateShort: 2020-Jun-26
:END:


** u/Transcendent_One:
#+begin_quote
  the core of the story is much more about the relationship between sapience and intelligence, and whether you need the first to have the other
#+end_quote

That's what I actually enjoyed the most in this story. Vampires felt kind of beside the point, like an exercise in "how could I describe vampirism scientifically". But I didn't encounter the idea of self-awareness not being a prerequisite of intelligence anywhere else.
:PROPERTIES:
:Author: Transcendent_One
:Score: 26
:DateUnix: 1593082940.0
:DateShort: 2020-Jun-25
:END:

*** u/Wizard-of-Woah:
#+begin_quote
  and, the characters and much of the social speculation left much less of an impact, even considering the interesting ideas that some of them were based around. Not they they were incompeten
#+end_quote

Yeah, I think the vampires are a touch shoe-horned in the first book. Which kind of makes sense. The vampires owe their genesis to Watts being press-ganged at a con into a vampire panel, because they wanted a "hard sf" representative. The vampires were something he just sort of made up on the fly.

So yeah, the vampires, to me at least, feel like a fun idea Watts was very fond of, but couldn't figure out a story for them specifically, so he added them into /Blindsight/ for a good pop-culture hook. For what it's worth, I think they add a lot more to the sequel.
:PROPERTIES:
:Author: Wizard-of-Woah
:Score: 16
:DateUnix: 1593087335.0
:DateShort: 2020-Jun-25
:END:

**** u/Transcendent_One:
#+begin_quote
  The vampires owe their genesis to Watts being press-ganged at a con into a vampire panel, because they wanted a "hard sf" representative. The vampires were something he just sort of made up on the fly.
#+end_quote

Wow, didn't know that. Nice to see my intuition confirmed in such a way :)
:PROPERTIES:
:Author: Transcendent_One
:Score: 7
:DateUnix: 1593110871.0
:DateShort: 2020-Jun-25
:END:


**** In the first book vampires tie into the theme of asking which traits give evolutionary advantage
:PROPERTIES:
:Author: crispin1
:Score: 4
:DateUnix: 1593144824.0
:DateShort: 2020-Jun-26
:END:

***** Yes, but the answer "not consciousness" could have been given entirely without fangs, vulnerability to right angles, or the v-word. Humans with intelligence but no consciousness could just as well be called 'zombies', or indeed 'werewolves'. The theme doesn't require vampires as the mythological monster to be resurrected.
:PROPERTIES:
:Author: King_of_Men
:Score: 3
:DateUnix: 1593147590.0
:DateShort: 2020-Jun-26
:END:

****** Sure, but you could also give that answer without writing a sci-fi novel or any novel at all. He fits the theme of everyone on the crew being very different, and reflecting on those differences supports the central theme. I admit I found it weird having a vampire in hard sci-fi but the weirdness of the book is one of its good aspects imo.
:PROPERTIES:
:Author: crispin1
:Score: 3
:DateUnix: 1593158280.0
:DateShort: 2020-Jun-26
:END:

******* I found the inclusion of the vampire to be a good insofar as it telegraphed from the beginning that this was really a horror novel at its heart.
:PROPERTIES:
:Author: callmesalticidae
:Score: 5
:DateUnix: 1593159883.0
:DateShort: 2020-Jun-26
:END:


****** There are zombies in echophraxia.

They are soldiers who have the ability to disable their consciousness to improve their combat capabilities.
:PROPERTIES:
:Author: Dancreepermaker
:Score: 4
:DateUnix: 1593305955.0
:DateShort: 2020-Jun-28
:END:


*** u/ArgentStonecutter:
#+begin_quote
  I didn't encounter the idea of self-awareness not being a prerequisite of intelligence anywhere else.
#+end_quote

Karl Schroeder, "Solitaire", /Permanence/, and the /Virga/ series.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 12
:DateUnix: 1593087720.0
:DateShort: 2020-Jun-25
:END:

**** The Hive in Bruce Sterling's /Schizmatrix/ (1985) also examines this idea.
:PROPERTIES:
:Author: loimprevisto
:Score: 4
:DateUnix: 1593099891.0
:DateShort: 2020-Jun-25
:END:

***** Possibly also Vacuum Flowers and Stations of the Tide by Michael Swanwick.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 6
:DateUnix: 1593100256.0
:DateShort: 2020-Jun-25
:END:


**** Thanks for the hint ([[/u/loimprevisto]], and to you too)! Didn't read any of these.
:PROPERTIES:
:Author: Transcendent_One
:Score: 2
:DateUnix: 1593110695.0
:DateShort: 2020-Jun-25
:END:


*** Thinking he was trying some thematic connection with the "can't see themselves in a mirror" or something like that.

But yeah, on the whole, I was also a bit surprised by the intrusion of the vampire theme.
:PROPERTIES:
:Author: ElitistOars
:Score: 5
:DateUnix: 1593138329.0
:DateShort: 2020-Jun-26
:END:


** Yes. Really enjoyed it. I particularly liked the way none of the main characters are neurotypical. Well written aliens too, with a genuinely different form of thought to our own. Also plenty of great descriptive work to appeal to the science fan; +1 for turning 'coriolis' into a verb.

Anyone planning to read it should know that discussions on this thread on the nature of intelligence etc may well turn into plot spoilers. OP may want to mark some of their post as such.

Although I don't remember the details, I found myself disagreeing with his take on all that stuff. There was some assumption or other underlying the whole argument that I rejected. Didn't detract from my enjoyment of the book, though.
:PROPERTIES:
:Author: crispin1
:Score: 20
:DateUnix: 1593089802.0
:DateShort: 2020-Jun-25
:END:

*** Advice taken.
:PROPERTIES:
:Author: Wizard-of-Woah
:Score: 5
:DateUnix: 1593090237.0
:DateShort: 2020-Jun-25
:END:


** Sapience is intelligence, the ability to understand the world in a sophisticated way. Sentience is the ability to experience the world via qualia, being conscious. Dogs are sentient, but not the most sapient, for example. Blindsight argues that we can be sapient without being sentient.

I really enjoyed the book. Its central premise is fascinating and thought provoking. I would recommend it.
:PROPERTIES:
:Author: fyfsixseven
:Score: 7
:DateUnix: 1593101439.0
:DateShort: 2020-Jun-25
:END:


** It's definitely relevant here, and has already been recommended a lot. Try this google search:

#+begin_example
  site:reddit.com/r/rational "blindsight"
#+end_example

Personally I didn't like it. There was no character I could identify with and root for. It felt very dystopian. And I didn't find the book's premise that you can have deep intelligence without consciousness believable. To each their own..
:PROPERTIES:
:Author: uwu-bob
:Score: 10
:DateUnix: 1593088294.0
:DateShort: 2020-Jun-25
:END:

*** Speculation: did you like HPMOR?
:PROPERTIES:
:Author: FeepingCreature
:Score: 4
:DateUnix: 1593097695.0
:DateShort: 2020-Jun-25
:END:

**** Yep I did, at least for 75% of the book. It got a bit long-winded. What was your theory?
:PROPERTIES:
:Author: uwu-bob
:Score: 3
:DateUnix: 1593103821.0
:DateShort: 2020-Jun-25
:END:

***** Damn. I thought liking Siri would correlate with liking Harry.
:PROPERTIES:
:Author: FeepingCreature
:Score: 4
:DateUnix: 1593119223.0
:DateShort: 2020-Jun-26
:END:

****** Anticorrelation here. Hpmor was too smartass for me overall. Possibly I didn't like that it reminded me of some of my own bad traits üòÜ. There were some good bits as well but I got bored and didn't finish it.

Fwiw I never read actual Harry Potter either and much though I wanted to like the films, felt they were made more for those who had read the books.
:PROPERTIES:
:Author: crispin1
:Score: 5
:DateUnix: 1593124509.0
:DateShort: 2020-Jun-26
:END:

******* Maybe it's that Siri is more clearly signalled as "ineffective and untrusted" through the story.
:PROPERTIES:
:Author: FeepingCreature
:Score: 4
:DateUnix: 1593133270.0
:DateShort: 2020-Jun-26
:END:

******** Hp was supposed to be that? Siri had humility, and uncertainty about his role both in the mission and the world in general. That made him likable.
:PROPERTIES:
:Author: crispin1
:Score: 5
:DateUnix: 1593144540.0
:DateShort: 2020-Jun-26
:END:

********* HP was supposed to come across as awesome but hint at underlying issues, which you had to slightly pay attention to pick up. (Because HPMOR is a coming of age novel...) Siri reads more like ... he doesn't come across as humble so much as handicapped. Also he's part of a competent military command structure so there tends to be less of the "arguments with authorities" that turn people off in HPMOR? I'd say that one depends on whether you believe Sarasti on Siri externalizing his disdain for Sarasti's authority. But I mean, they both have a dark side and a seemingly logical/explicit approach papering over social deficiencies and self-unawareness. I feel like they'd be good friends.
:PROPERTIES:
:Author: FeepingCreature
:Score: 6
:DateUnix: 1593146891.0
:DateShort: 2020-Jun-26
:END:

********** I read Siri differently but agree him and HP would likely get along!
:PROPERTIES:
:Author: crispin1
:Score: 2
:DateUnix: 1593162589.0
:DateShort: 2020-Jun-26
:END:


*** I think it's /meant/ to be dystopian. This is a world without hope, or heroes, where an increasing percent of its population is flat-out opting out. IMO echopraxia makes it even darker.
:PROPERTIES:
:Author: overzealous_dentist
:Score: 4
:DateUnix: 1593112157.0
:DateShort: 2020-Jun-25
:END:


*** Exactly, it didn't feel like the characters were relatable, they just accepted dystopia as normal, and the ‚Äúintelligence without consciousness‚Äù felt more like the characters and/or author simply finding aliens' consciousness too, well, alien to recognize. I enjoyed the explanation of Chinese Box A.I. and the vampires though.
:PROPERTIES:
:Author: Zarohk
:Score: 4
:DateUnix: 1593096760.0
:DateShort: 2020-Jun-25
:END:

**** u/Transcendent_One:
#+begin_quote
  they just accepted dystopia as normal
#+end_quote

Actually, I would expect that of most people living in a dystopia, real or fictional.
:PROPERTIES:
:Author: Transcendent_One
:Score: 9
:DateUnix: 1593114551.0
:DateShort: 2020-Jun-26
:END:


** You know what's sad? I can totally see vampirism being marketed as an autism cure. Like, how many parents would pick "superhuman sociopath" over "son who doesn't do eye contact well"?
:PROPERTIES:
:Author: Wizard-of-Woah
:Score: 4
:DateUnix: 1593100793.0
:DateShort: 2020-Jun-25
:END:

*** For correctness, Siri Keeton (the protagonist) isn't a vampire. He's a human who had radical surgery performed on him as a child.

Sarasti, the captain of the ship, is a vampire- he's a completely different species that humans used biotechnology to resurrect. Neurologically, the book implies that vampires are less sentient than humans but have the advantage of multiple simultaneous thoughts occuring in parallel.

Vampirism isn't a treatment, it's being a completely different species.
:PROPERTIES:
:Author: WhispersOfSeaSpiders
:Score: 7
:DateUnix: 1593103133.0
:DateShort: 2020-Jun-25
:END:

**** Oh, I didn't meant to imply Siri was a vampire. I was referring to the fact that, in the background material, it's revealed the vampire genotype was discovered in an attempt to cure autism with a retrovirus, which resulted in the first human test subject--an autistic nine year old--becoming a vampire. The idea being that autistic traits are at least in part a legacy of vampiric genetics. Savant skills and all that.

[[https://rifters.com/blindsight/vampires.htm]]
:PROPERTIES:
:Author: Wizard-of-Woah
:Score: 8
:DateUnix: 1593103714.0
:DateShort: 2020-Jun-25
:END:

***** Also available [[https://m.youtube.com/playlist?list=PL30ED0756E00786E2][on YouTube]]
:PROPERTIES:
:Author: IndulgencesForSale
:Score: 3
:DateUnix: 1593147821.0
:DateShort: 2020-Jun-26
:END:


***** Interesting! The link you sent does just read "Redacted," by the way.
:PROPERTIES:
:Author: WhispersOfSeaSpiders
:Score: 2
:DateUnix: 1593105250.0
:DateShort: 2020-Jun-25
:END:

****** Do you have flash enabled?
:PROPERTIES:
:Author: Wizard-of-Woah
:Score: 2
:DateUnix: 1593105308.0
:DateShort: 2020-Jun-25
:END:

******* After checking, I was able to see the embedded video using Chrome (Firefox oddly enough didn't seem to have the Flash extension at all).

This was great, by the way. The researchers certainly sell hard the idea that this was a cure for autism.
:PROPERTIES:
:Author: WhispersOfSeaSpiders
:Score: 3
:DateUnix: 1593106710.0
:DateShort: 2020-Jun-25
:END:


** I liked it as a sci-fi but didn't liked it as a book. The ideas are great the execution is so-so. It felt disjointed and I wasn't empathizing with any character.
:PROPERTIES:
:Author: ajuc
:Score: 3
:DateUnix: 1593097318.0
:DateShort: 2020-Jun-25
:END:


** I will say this, I kinda wish we'd gotten to see inside a posthuman's head at some point. Maybe Valerie the vampire in the sequel? I know they're supposed to be incomprehensible, but xenofiction is a proud literary tradition.
:PROPERTIES:
:Author: Wizard-of-Woah
:Score: 2
:DateUnix: 1593108143.0
:DateShort: 2020-Jun-25
:END:

*** It isn't that they're incomprehensible per se, but that they're far smarter than the author is, and Watts recognizes that it's very difficult to write characters who are much more intelligent than you are.
:PROPERTIES:
:Author: callmesalticidae
:Score: 5
:DateUnix: 1593160091.0
:DateShort: 2020-Jun-26
:END:


** I was torn about this book, as on all Watts books.

One one hand, the writing is brilliant, the plot is masterfully crafted and the world and ideas are just perfect in their sci-fi hardness.

On the other hand, the characters are all unlikable, the tone is bleak and depressing, and the whole theme borderlines on grimdark.

I would say that reading Blindsight was an absolute thrilling experience, but not a pleasant one.
:PROPERTIES:
:Author: Freevoulous
:Score: 2
:DateUnix: 1593452460.0
:DateShort: 2020-Jun-29
:END:


** I really wanted to listen to it for a while. Sadly German Audible doesn't carry it. Though there appears to be an amateur reading of it on YouTube, so I might give it a try soon.
:PROPERTIES:
:Author: DavidGretzschel
:Score: 1
:DateUnix: 1593207529.0
:DateShort: 2020-Jun-27
:END:


** Yes, because [[http://www.rifters.com/real/Blindsight.htm][it's free to read online.]]

The vampire stuff is too hackneyed and silly for me, all it served was to bookend the futility of it all and a greygoo nanomachine monster could have done the same and been more rational.

What I do like very much is how it presents humans as rather inferior, which I feel like is completely necessary in a sci-fi setting that has any sufficiently advanced AI.

Space Fantasy Star Trek TNG never made a bit of sense logically, unless you assumed it was a Matrix/Sword Art Online fantasy world and Picard was cosplaying in a video game. Otherwise it buggers belief that they don't just have a robot doing the daring-do.

I read complaints about how the characters are freaks that had to modify themselves to the extreme just to still be obsolete, and it's like what... you want humans to be a shonen protagonist in a world with mechanical super intelligence? You want someone willing to augment themselves to the extreme, to have the personality of a normie like the people in the alternate reality box? These things can't co-exist without embracing complete fantasy.
:PROPERTIES:
:Author: IronPheasant
:Score: 1
:DateUnix: 1593471273.0
:DateShort: 2020-Jun-30
:END:


** <associative cortex reacts to the stimulus by throwing up two particular moments>

---

"That thing which is your one job, which is the whole reason we brought you along? You're actually terrible at it, seeing completely wrong things that you want to see instead."

---

[Flashback] "Hey, I've thought of an argument from the Prisoner's Dilemma for a certain unintuitive social behaviour (which the reader can probably think of compelling counterarguments for)." [/Flashback]

"...And then she (my girlfriend) laughed at my face and refused to discuss why she was laughing, whether she agreed or disagreed with me, and whether she had spotted anything I'd overlooked in my reasoning."

"Well, /I/ wouldn't have laughed. /I/ would have immediately dumped you. Having given you this stinging put-down, I now also refuse to discuss why I'd do that or whether I see any problems in your reasoning."
:PROPERTIES:
:Author: MultipartiteMind
:Score: 1
:DateUnix: 1593136793.0
:DateShort: 2020-Jun-26
:END:

*** u/FeepingCreature:
#+begin_quote
  "That thing which is your one job, which is the whole reason we brought you along? You're actually terrible at it, seeing completely wrong things that you want to see instead."
#+end_quote

Note that Sarasti disregarded Siri's intuition at his (imminent) peril. I don't think this is the story asserting Siri is terrible at it so much as a character.

edit: Also the ending is kind of appropriate, no? The topology Siri is meant to translate isn't Starfish to Theseus, it's Theseus to Earth, or rather to us, given how Earth is kind of dying.
:PROPERTIES:
:Author: FeepingCreature
:Score: 1
:DateUnix: 1593147238.0
:DateShort: 2020-Jun-26
:END:


** There is definetely some set of aesthetic standards that links ratfics and Blindsight together. You know, the rationalist mouthpieces going around constantly dropping science factoids and science theories. And of course, the characters who aren't rationalists are depicted as uneducated ones. Like it's talking down to the reader about why rationalism is ze best.

But doesn't the Watts' book feel like kinda Anti-Yudkowsky deconstruction with its carpet-bombing the value of sentience and compassion?
:PROPERTIES:
:Author: crnislshr
:Score: -1
:DateUnix: 1593081678.0
:DateShort: 2020-Jun-25
:END:

*** Well, if we define rationality as a set of Yudkowsky's dogmatic teachings, then maybe. But if we use even Yudkowsky's own definition "rationality is systematized winning", then the question "is self-awareness valuable for winning?" is just as legitimate as any other.
:PROPERTIES:
:Author: Transcendent_One
:Score: 11
:DateUnix: 1593082530.0
:DateShort: 2020-Jun-25
:END:

**** I'd argue that that definition can't really be used here, because (as others have pointed out) "winning" is a term whose precise meaning varies between individuals. You'd change the meaning of that sentence at least a little if you tried to translate it into different human cultures and/or languages, nevermind the mess that results when you try to apply it to non-sentient beings with no concept of language.

If I had to term 'rationality', I'd call it...

#+begin_quote
  A term broadly referring to the absolute level of efficiency and effectiveness with which a complex system affects changes on it's environment, particularly when those changes fall into consistent categorizations such as, but not limited to,

  'Increasing the probability of the continued existence of the complex system.' or

  'Increasing the susceptibility of the environment to change by the complex system.' or

  'Increasing the rationality of the complex system.'
#+end_quote

I would say this definition captures the essence of rationality, /without/ having to involve such incredibly messy, subjective, and difficult-to-define words as 'conscious', 'winning', 'sentient', 'sapient', etc. And it can be applied to humans, the aliens in question, and just about anything else that would be defined as a 'intelligent being'.
:PROPERTIES:
:Author: Buggy321
:Score: 1
:DateUnix: 1593103527.0
:DateShort: 2020-Jun-25
:END:

***** I think it's a /feature/ of 'winning' that it's varied, i.e. dependent on what individuals want (or maybe what 'enlightened'* versions of individuals want).

- I'm hinting at, not that there's 'a unique optimal utility function' (for all humans), but that for any specific /human/ approximation to something like a utility function (i.e. whatever it is that we /do/ use), there /is/ probably something like a 'unique optimal utility function' for /each/ approximation, and that almost everyone is very far from acting according to that 'enlightened' version.
:PROPERTIES:
:Author: kryptomicron
:Score: 2
:DateUnix: 1593120578.0
:DateShort: 2020-Jun-26
:END:

****** (bit of a rambling post, sorry.)

I agree that you can more-or-less assign humans (individual-specific) utility functions, define 'winning' as optimizing it, and then define rationality as winning.

But the entire ongoing argument in the other comment threads is based on "winning" specifically and whether or not that term, which is intimately tied to language and the self, is meaningful when it comes to nonsentient beings with no concept of language. The normally-significant ambiguity that people tend to overlook with words is cranked up so far that you can't even begin to figure out the specific definition that the Scramblers would use, because they don't even have language.

So in my eyes, the problem is that /no one is considering other possible definitions for 'rationality'/. The given definition would otherwise be fine, but it just doesn't work properly in this context. So offering a more general definition that doesn't (or at least tries not to) make a bunch of assumptions about the nature of the intelligence involved is prudent.

Also, on a bit of a side note, I bring up the whole "words mean different things to different people, and entire arguments can hinge on that" because everyone is talking about consciousness, sapience, sentience, etc, and, speaking for myself, I have /no idea what those are/ or how they're being used here. Not for lack of thinking or reading about it, either.

Am I conscious? How would I tell? Is it hinged on the ability to recognize one's self as existing in the world and make changes utilizing that realization? Because lots of things can do that; /ants/ can pass the mirror test. And the Scramblers do too, they apparently just don't see themselves as individuals; when one was asked to identify another Scrambler it said 'Rorschach', the ship they were a part of. That's a bit like if you asked a ant to identify another ant and it said "That is Colony." And it goes without saying that they're capable of understanding that injury or death is a impedance.

Does that mean that Scramblers /are/ conscious and self-aware? Are they /not/ conscious or self aware just because they only care about the well-being of their colony/ship and don't bother with individuality? Because if so, you could say that a sufficiently dedicated soldier for whatever country is also less or non-conscious, if they're putting the wellbeing and needs of their country above their lives. Or that individuals from any cultures which value the group more heavily than personal identity are also less or non-conscious.

Are they non-conscious because they don't understand or use language? Are humans who are (metaphorically, literal cases are rare) raised by wolves, and end up with no concept of language non-conscious? GPT-3 is reasonably competent with language, it can regularly write text indistinguishable from human-written text, is it /conscious/? Is the Chinese-room that Rorschach utilized conscious, or is it not conscious because it broke down when it faced a context outside what it was normally equipped for? Because a similar thing can happen with humans with poor language skills.

All of these are very important points, and I'd wager that no one should even be /using/ these words in a argument until some sort of consensus is reached and we know we're using similar definitions, because otherwise we're basically arguing completely different points and it doesn't take a rationalist to know that's bad in a debate.

But we are, and it bugs me.
:PROPERTIES:
:Author: Buggy321
:Score: 2
:DateUnix: 1593124078.0
:DateShort: 2020-Jun-26
:END:

******* No worries on a /long/ post -- totally disagree about it being /rambling/ tho :)

I don't think 'winning' is tied to language. I wouldn't trust /humans/ to be able to accurately even approximate the actual 'approximation' of their utility functions.

I also don't always know what people mean by 'consciousness', 'sapience', 'sentience', etc.. I'm inclined to think that they're more the result of our confusion than anything. I wouldn't be surprised if they weren't used by future people with better understanding of 'intelligence'.

(I haven't read Blindsight yet myself but I've read about it and have a copy to-read too.)

The 'not seeing themselves as individuals' is confusing to me. I can better understand it if the individual Scramblers were, in a real concrete sense, a 'single mind', like the tines in A Fire Upon the Deep. So, one Scrambler identifying another as "Rorschach" /should/ also (easily) understand that their statement was equivalent to "That's another part of me, Rorschach. I am the ship.".

I do remember reading something recently, that linked to a bunch of examples elsewhere too, of people claiming that they remember 'waking up as conscious', e.g. as a teenager. (It might have been the comments on Slate Star Codex's recent post reviewing the 'bicameral mind' book.) Like with other mental epiphenomena, those of us that /are/ conscious might be just /assuming/ that all other people are too, when they aren't. I'll admit that seems like a stretch.

I sympathize with your lament about imprecise definitions, but that seems inevitable when discussing confusing/confused topics. It's perfectly fine to debate or discuss those definitions -- examples help! It's also fine to just taboo the unclear words and directly debate or discuss whatever you think are the relevant aspects or components.
:PROPERTIES:
:Author: kryptomicron
:Score: 1
:DateUnix: 1593125994.0
:DateShort: 2020-Jun-26
:END:


**** u/King_of_Men:
#+begin_quote
  the question "is self-awareness valuable for winning?" is just as legitimate as any other.
#+end_quote

Ok, but the answer is clearly "self-awareness is required to win, because otherwise who experienced the victory?" A computer does not win at chess; it moves electrons around until a stop condition is reached. 'Winning' is a thing that conscious beings do; victory being a state of mind, it requires a mind to experience it. The question Blindsight raises is rather whether self-awareness is valuable for /reproducing/, which is not the same thing.
:PROPERTIES:
:Author: King_of_Men
:Score: 1
:DateUnix: 1593147857.0
:DateShort: 2020-Jun-26
:END:

***** Well, first of all, victory itself can be experienced without as well as anything else; self-awareness is needed for inspecting one's own mental state during it. And then, if computers don't win at chess, then why do humans? They also do nothing but moving atoms around. Such a simplistic reductionism doesn't lead anywhere, it just derails us into looking for a metaphysical boundary, beyond which chess suddenly emerges from a bunch of atoms.
:PROPERTIES:
:Author: Transcendent_One
:Score: 1
:DateUnix: 1593191456.0
:DateShort: 2020-Jun-26
:END:

****** Victory cannot be experienced without experiencing. A non-conscious mind does not experience anything, that's rather the point. I'm taking 'self-aware' and 'conscious' as synonyms here, as Blindsight also seems to do; the vampires are non-conscious in that there is nothing that it is like to be them, any more than there is something that it's like to be a desk.

I do not know why humans are conscious and computers are not, but I see no need to call the boundary metaphysical: Clearly the physics of a human brain is very different from the physics of a Neumann-architecture computer. I'm not claiming that it's impossible to build a conscious computer (which indeed would win chess games), only that current computers are not conscious.
:PROPERTIES:
:Author: King_of_Men
:Score: 0
:DateUnix: 1593191945.0
:DateShort: 2020-Jun-26
:END:


**** "Is winning valuable for winning?"\\
"Is value valuable?"
:PROPERTIES:
:Author: crnislshr
:Score: -6
:DateUnix: 1593082675.0
:DateShort: 2020-Jun-25
:END:

***** u/Transcendent_One:
#+begin_quote

  #+begin_quote
    "is self-awareness valuable for winning?"
  #+end_quote

  "Is winning valuable for winning?"
#+end_quote

Are you equating self-awareness with winning by definition?
:PROPERTIES:
:Author: Transcendent_One
:Score: 4
:DateUnix: 1593083012.0
:DateShort: 2020-Jun-25
:END:

****** Winning is the act of one that wins.\\
If there're no "you", who is supposed to "win" and what is the difference between "winning" and "losing"?
:PROPERTIES:
:Author: crnislshr
:Score: 4
:DateUnix: 1593083301.0
:DateShort: 2020-Jun-25
:END:

******* u/ArgentStonecutter:
#+begin_quote
  If there're no "you", who is supposed to "win" and what is the difference between "winning" and "losing"?
#+end_quote

What survives, wins. That's evolution. Sapience is a strategy for survival. The question in Watts and Schroeder's work is whether it's the best such strategy or even over the long term a good one.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 9
:DateUnix: 1593087918.0
:DateShort: 2020-Jun-25
:END:

******** Is evolution or survival have any inherent meaning except what we give them as individuals? You can notice that it is perfectly normal and natural for everything to die / go extinct in its normal course.
:PROPERTIES:
:Author: crnislshr
:Score: 3
:DateUnix: 1593089208.0
:DateShort: 2020-Jun-25
:END:

********* You can't win.

You can't break even.

You can't walk away from the table.

Life is empty and meaningless.

Meaning is a category error.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 5
:DateUnix: 1593089275.0
:DateShort: 2020-Jun-25
:END:

********** See? If we throw away the "self" in the search of winning, we prove by contradiction that winning can be defined only based on the axiome of "self".
:PROPERTIES:
:Author: crnislshr
:Score: 3
:DateUnix: 1593090012.0
:DateShort: 2020-Jun-25
:END:

*********** Searching is a category error.

Contradictions are a category error.

Axioms are a category error.

The self is a category error.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 2
:DateUnix: 1593091775.0
:DateShort: 2020-Jun-25
:END:

************ And category error is a category error as well.\\
The doubter or skeptic never thinks he is right, he never thinks that there is any right, but neither does he thinks there is any wrong, if he is sincere in his scepticism. He really cannot think at all, because thinking involves accepting certain things that cannot be proved, but can only be accepted on faith.\\
All thinking begins with assumptions that cannot be proved in logic, we call these axioms. But the real skeptic has nowhere to begin because he must doubt everything and so, so he sinks through floor after floor of a bottomless universe.\\
Reason can only be built on faith and that faith is the foundation of our civilization and our self-awareness.
:PROPERTIES:
:Author: crnislshr
:Score: 2
:DateUnix: 1593092186.0
:DateShort: 2020-Jun-25
:END:

************* You sound very intelligent, but you're trying to make yourself an axiom in a system that you're only the result of.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 3
:DateUnix: 1593095278.0
:DateShort: 2020-Jun-25
:END:

************** Making or acknowledging?

From your subjective perspective, you have no possibility to judge surely what is more illusionary, "you" or the "system."

Even the separation between "objectivity" and "subjectivity" in your mind is illusionary.

However, the "self" is self-made. Once you have the "illusion of self", you have the "illusionary meanings" for yourself. And obviously, all the attempts to act and think as not-self are second order illusions -- and the fragility of these illusions is easily proved by pain for the first order illusion of "your self".

How is it typically solved? We take the concept of Truth. To the question, "What are you?" you answer, "Truth knows." And to the question, "What is meant by it?" -- if you're sincery, you only can start to answer with "That whatever I am, I am not myself."

And once a thinker has thought to a definite end, the person can be called dogmatist.

It's just you can accept dogma and know it, and you can accept dogma and don't know it.
:PROPERTIES:
:Author: crnislshr
:Score: 1
:DateUnix: 1593097626.0
:DateShort: 2020-Jun-25
:END:

*************** Making.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 1
:DateUnix: 1593100156.0
:DateShort: 2020-Jun-25
:END:

**************** You look in the mirror and make the assumption "It's me". In the world that you're only the result of. Of course, it's not you, it's just your reflection.

#+begin_quote
  Shee was as light\\
  As Mee, and as bright;\\
  But Shee was, strange to tell,\\
  Hanging down\\
  With starry crown\\
  Into a bottomless well!\\
  Her gleaming eyes\\
  In great surprise\\
  Looked upon to the eyes of Mee:\\
  A marvellous thing,\\
  Head-down to swing\\
  Above a starry sea!

  Only their feet\\
  Could ever meet;\\
  For where the ways might lie\\
  To find a land\\
  Where they do not stand\\
  But hang down in the sky\\
  No one could tell\\
  Nor learn in spell\\
  In all the elven-lore.
#+end_quote

[[http://tolkiengateway.net/wiki/Little_Princess_Mee]]
:PROPERTIES:
:Author: crnislshr
:Score: 1
:DateUnix: 1593101062.0
:DateShort: 2020-Jun-25
:END:

***************** It's also a shadow in a cave.
:PROPERTIES:
:Author: ArgentStonecutter
:Score: 2
:DateUnix: 1593101108.0
:DateShort: 2020-Jun-25
:END:

****************** "Power resides where men believe it resides. It's a trick, a shadow on the wall. Yet shadows can kill."
:PROPERTIES:
:Author: crnislshr
:Score: 1
:DateUnix: 1593101603.0
:DateShort: 2020-Jun-25
:END:


******* A possible method, for example, would be ascribing "goals" to non-self-aware agents, based on what do they tend to do, how does their behaviour change in various conditions, etc., and evaluating their performance with relation to these "goals". Of course, this is just a projection, it could be potentially faulty; in a universe where self-aware lifeforms went extinct and non-self-aware ones dominated, the self-aware ones could argue about self-awareness being necessary for the "win" to count...oh wait, they couldn't.
:PROPERTIES:
:Author: Transcendent_One
:Score: 2
:DateUnix: 1593083965.0
:DateShort: 2020-Jun-25
:END:

******** See? You need self-aware ones to to ascribe "goals" to non-self-aware ones and to argue about "winning".

For example, you can make the decision to die/become non-self-aware to achieve something. But the value of the achievement in question still is a subjective value which was reflected in your self-aware conciousness. You think about the value of the wanted achievement as about something applying to the question "who am I?"
:PROPERTIES:
:Author: crnislshr
:Score: 2
:DateUnix: 1593085586.0
:DateShort: 2020-Jun-25
:END:

********* u/FeepingCreature:
#+begin_quote
  See? You need self-aware ones to to ascribe "goals" to non-self-aware ones and to argue about "winning".
#+end_quote

You don't need it to win though.
:PROPERTIES:
:Author: FeepingCreature
:Score: 5
:DateUnix: 1593097745.0
:DateShort: 2020-Jun-25
:END:

********** It seems. Still...\\
You will become a powerful P-zombie who will rule the world and will breed with beautiful women or whatever dreams you had before. Do you yourself right now define it as a victory? Or are there some nuances?
:PROPERTIES:
:Author: crnislshr
:Score: 2
:DateUnix: 1593099623.0
:DateShort: 2020-Jun-25
:END:

*********** u/Transcendent_One:
#+begin_quote
  Do you yourself right now define it as a victory? Or are there some nuances?
#+end_quote

Does it matter? If I don't, that would only mean that my utility function involves self-awareness as a value in itself, not as means to an end (and the value ascribed to it is greater than the value of any achievements of my hypotethical unaware self).
:PROPERTIES:
:Author: Transcendent_One
:Score: 2
:DateUnix: 1593110422.0
:DateShort: 2020-Jun-25
:END:


******* I guess you could equate 'winning' with 'able to survive against increasingly greater levels (and number of types?) of destructive forces and/or circumstances'. Usually meaning growing or expanding, but maybe also evolving to be /able/ to grow in new places which weren't survivable before.
:PROPERTIES:
:Author: Geminii27
:Score: 2
:DateUnix: 1593088158.0
:DateShort: 2020-Jun-25
:END:


** Read it. Didn't really like it.

‚Äã

SPOILERS

The vampire addition felt pointless to the whole theme. The intelligence without sentience argument did not convince me. IMHO to compete and evolve you need to model the future and hence you need to work with very abstract objects. I believe sentience derives from there. Maybe I'm just stupid and I didn't get some of his arguments. Also monster did not feel interesting.
:PROPERTIES:
:Author: hoja_nasredin
:Score: 0
:DateUnix: 1593102661.0
:DateShort: 2020-Jun-25
:END:


** u/RMcD94:
#+begin_quote
  Has anyone here read Peter Watts' Blindsight?
#+end_quote

[[https://www.reddit.com/r/rational/search?q=blindsight&restrict_sr=on]]

Why not word the title as "Let's discuss Blindsight?"

If you wanted to know if anyone has read it you could have used the search bar or looked in the monthly recommendations where Blindsight justifiably gets regularly posted.

I know as this subreddit gets more readers people will do these titles but I hope we can be more like [[/r/askhistorians]]

In fact I think even askreddit would not allow this question

Regardless you can use the link above to see previous discussion threads on this topic
:PROPERTIES:
:Author: RMcD94
:Score: 0
:DateUnix: 1593107246.0
:DateShort: 2020-Jun-25
:END:

*** I think re-posts are fine to a large extent, on any sub (or similar 'venue'). Once a day is probably too much even for the largest subs, but, based on the search to which you linked, this book hasn't been discussed in over a year. No sub is going to be composed of the same people over periods that long. (And it's an inevitable tragedy of all old-timers to 'constantly' see the same things brought up by newcomers.)

#+begin_quote
  In fact I think even askreddit would not allow this question
#+end_quote

This seems particularly ironic given that I have /recently/ noticed a surprising amount of near-duplicate reposts on [[/r/AskReddit][r/AskReddit]].
:PROPERTIES:
:Author: kryptomicron
:Score: 3
:DateUnix: 1593121012.0
:DateShort: 2020-Jun-26
:END:

**** u/RMcD94:
#+begin_quote
  I think re-posts are fine to a large extent, on any sub (or similar 'venue'). Once a day is probably too much even for the largest subs, but, based on the search to which you linked, this book hasn't been discussed in over a year. No sub is going to be composed of the same people over periods that long. (And it's an inevitable tragedy of all old-timers to 'constantly' see the same things brought up by newcomers.)
#+end_quote

Sure that's why a better framing would be "let's discuss Blindsight" rather than "has anyone..."

#+begin_quote
  This seems particularly ironic given that I have recently noticed a surprising amount of near-duplicate reposts on [[/r/AskReddit][r/AskReddit]].
#+end_quote

Well you're not allowed yes/no questions on askreddit
:PROPERTIES:
:Author: RMcD94
:Score: 0
:DateUnix: 1593121825.0
:DateShort: 2020-Jun-26
:END:

***** I agree about the title, but don't think it's that much better to even be worth mentioning. I'd imagine they're functionally equivalent.

I didn't know about the 'yes/no question thing, but again, that's probably silly as the yes/no questions seem to be near-universally understood to be prompts to discuss the topic and not literal queries.
:PROPERTIES:
:Author: kryptomicron
:Score: 2
:DateUnix: 1593122126.0
:DateShort: 2020-Jun-26
:END:


** Blindsight felt like the science fiction version of some book written by a crank who has an incredibly questionable belief about a field of science outside of their expertise. Which, to be fair, could be said about a lot of science fiction novels, and isn't necessarily a bad thing. But Blindsight is pretty standout due to the pessimism about it all.

Honestly the premise seems to me as kind of humanocentric in a roundabout cynical way, because by positing sapience and self-awareness as unique to humanity it's basically discounting the idea that there could be other kinds of sapience that we as humans would have trouble recognizing as such. In the same way that we often discount the intelligence and emotionality of some species of animals because they don't express it in ways we can relate to.
:PROPERTIES:
:Author: muns4colleg
:Score: -3
:DateUnix: 1593127773.0
:DateShort: 2020-Jun-26
:END:
