#+TITLE: Ra: It Has To Work

* [[http://qntm.org/work][Ra: It Has To Work]]
:PROPERTIES:
:Author: VorpalAuroch
:Score: 16
:DateUnix: 1406184126.0
:END:

** Is it bad that I'm cheering for the VR people (and thus Ra) most of the time?

I mean, sure, there's a couple billion people on the line here, but theres millions more 'frozen' in Ra's VR, and the resources these couple billion people are using could presumably host orders of magnitude more people if they were being used efficiently.
:PROPERTIES:
:Author: Anderkent
:Score: 3
:DateUnix: 1406210045.0
:END:

*** I don't have a lot of respect for the Virtuals, considering that they've been depicted as nothing more than lotus eaters. To me, that's not an acceptable end game for humanity. That's not even to mention the fact that they were the ones to fire the first shot in the war (assuming that's true). So basically, you're siding with a section of humanity that's decided genocide was the proper way of dealing with the fact that they want to have more fun.
:PROPERTIES:
:Author: alexanderwales
:Score: 4
:DateUnix: 1406215457.0
:END:

**** Since the virtual humans outnumber the reality humans millions to one it's a bit like the US not having proper mental health treatment for schizophrenia. The extra deaths of 159 kinda weird people isn't a massive priority compared to the lives of 318 million. And these 159 people are taking up a quarter of the budget.

It's sad but you can understand the morality. The ability for an extra hundred million people to be able to live is more important than 159 schizos.

It'd be nicer if some compromise was reached but in terms of ratios if you don't think about people with mental health issues dying as a serious issue as weighty as genocide 1/2 million humans dying isn't a huge moral concern for most humans.

Edit. And so I feel that you can't rely on morality to dictate what should be done in these questions. You should instead ensure you have adequate weaponry and security instead. You can rely on others thinking "Killing people with no reason is bad." Not on them thinking "Killing a tiny minority for the good of the majority is bad."
:PROPERTIES:
:Author: Nepene
:Score: 3
:DateUnix: 1406254491.0
:END:


**** Consider the source, though. The only image of Virtuals we have is from the Reals, who themselves admit they don't understand Virtuals any more.

And the Reals are pretty much lotus eaters too, except much more wasteful. They lock down technology to avoid any kind of progress, and just sit in a static environment while watching the 'new humanity' re-do all the work, so that they can 'enjoy the /true/ human experience'. That's... Probably the same thing the least productive virtuals are doing? After all maximising happiness is not about flooding yourself with drugs; every uploaded person that's focusing on that is doing art, or re-discovering physics, or other similarly fulfilling tasks.

(and maybe most of them aren't doing real progress; though progress when the AI has 'solved' the world is difficult to define; but at worst they're the same as the reals, and the possibilities for actual productivity are greater - they could be planning to expand to other solar systems (or perhaps already have, and the reals just didn't notice), working on simulation efficiency, etc.)

Presumably at the point where the new humanity would actually become able of doing something new, the wheel would reset them in fear of them uploading again (since uploading lets one be much more productive).

As for being the ones to start the war, at /some/ point the wastefullness of Reals must become grating. It's like... Imagine you're in a food-constrained country, and must limit your population to a constant number, while the country next to you has thousands more arable land, but they insist on using it inefficiently. You could give them the new technology, and with no impact on their quality of life allow both you and them to increase population.

That's how I see the Reals' refusing to upload.
:PROPERTIES:
:Author: Anderkent
:Score: 2
:DateUnix: 1406217367.0
:END:

***** It's funny <I'll find the quote latter> but Banks already commented on how intelligent life eventually developed rules about Hegemonizing swarm, which these virtuals seem to be, and the disposition of matter. The rules boiled down to ~"you can't take other people's stuff"

Besides why eat Earth when you can eat Mercury and get a head start on starlifting?
:PROPERTIES:
:Author: Empiricist_or_not
:Score: 2
:DateUnix: 1406229432.0
:END:

****** I think the point wasn't to eat earth, but to eat the one-eight of the sun energy output that was allowing earth to exist.

"You can't take other people's stuff" is a nice guideline but it breaks down when stakes are high. I think it's intuitive that if, say, you have a starving child and you stole some food to feed them, that's excusable, if not right. Rules have exceptions; that's why they're not laws.
:PROPERTIES:
:Author: Anderkent
:Score: 1
:DateUnix: 1406229946.0
:END:


***** Oh, I definitely agree that the Actuals aren't that much better, and the last remnant (the Wheel group) are completely unhinged. But a neighbor using land inefficiently doesn't justify genocide. Like, at all.
:PROPERTIES:
:Author: alexanderwales
:Score: 1
:DateUnix: 1406217897.0
:END:

****** Is it genocide if you can bring the people back later on and they'd be never-the-wiser? So it's basically just a couple months of torment.

And I dunno, even if it is genocide, if the scale of wasted resource is significant enough, surely it justifies the war? You're basically putting a billion existing people against orders of magnitude more of possible people, were they not so wasteful. Maybe possible people count less, but they aren't insignificant; if the ratio is big enough, the right thing to do is certainly to take the resources yourself.

The obvious case if we ignore the person / possible person distinction is to take one rich person, hogging and wasting food, in a starving city. Surely taking the food away from him and distributing to the people dying of hunger is right.
:PROPERTIES:
:Author: Anderkent
:Score: 1
:DateUnix: 1406218313.0
:END:

******* #+begin_quote
  The obvious case if we ignore the person / possible person distinction is to take one rich person, hogging and wasting food, in a starving city. Surely taking the food away from him and distributing to the people dying of hunger is right.
#+end_quote

The city isn't starving - all the other people are well-fed and happy. All indications are that the Virtuals are living the same kind of idyllic utopia lives that the Actuals were. So the only real argument is that there should be as many people as possible in the world, which I'm not sure that I agree with, since it would mean that maximizing population is de facto a good thing. And if the cost is genocide ... I'm just not seeing it as anything but an act of aggression. "You have stuff that we want" is not, to me, a morally valid reason to go to war.
:PROPERTIES:
:Author: alexanderwales
:Score: 2
:DateUnix: 1406230573.0
:END:


**** Do we have evidence that it was actually genocide, instead of forced (destructive) uploading?
:PROPERTIES:
:Author: reginaldshoe
:Score: 1
:DateUnix: 1406228421.0
:END:

***** I'd have to read through the relevant chapters again, but the big problem is that our viewpoints on the war are all from the Actuals themselves, and they're not reliable sources. However, the weapons used didn't seem to indicate to me that anything was being done with brains - you don't fire giant lasers at people if you want to recover what's in their heads.
:PROPERTIES:
:Author: alexanderwales
:Score: 1
:DateUnix: 1406230805.0
:END:


*** It depends heavily on what kind of society the Virtuals had in the beginning.

My interpretation was that the Virtuals were a bit similar to the Vile Offspring from Accelerando in that you can't really be sure what's happens in that world anymore because you can't comprehend any of it. So you can't be sure how worthwhile their lives are, if any. I think it's implied that in Accelerando capitalist competition eventually makes sentient beings obsolete inside the Dyson sphere.

Anyway, this is how Virtuals' society supposedly was:

#+begin_quote
  The new worlds would be tuned to whatever anybody could ask for, and to live in them would be as easy or as difficult as any human wanted. Rather than conquer the universe, they would write a fiction in which they had already conquered it. Infinite fun space.
#+end_quote

If the rules of that VR society aren't perfectly thought out beforehand, then the fast pace of computation relative to normal life means that the rules are extrapolated to their logical conclusion and any selection effect in the original rules changes the nature of the beings very quickly. See [[http://www.nickbostrom.com/fut/evolution.html][this]] and [[http://slatestarcodex.com/2014/07/13/growing-children-for-bostroms-disneyland/][this]] about those kind of selection effects. This kind of selection effect could happen in "fun society" too, if the fun includes a lot of interaction and zero-sum games of significance (like status competition). For example it could turn out that the ultimate form of fun is to make others miserable by dominating them in games and these have to be real people because defeating pseudo-people is like loving pseudo-people who cannot love, e.g. pretty lame. So then people modify themselves to adapt to these game and so on. There could be lots of these kind of "unknowns" that hide in the system and would lead to nasty results if extrapolated to their logical conclusion. A "fun society" could optimize for many things we're not aware of and selection effect is not the only kind of development that could lead to unforeseen consequences.

So it depends on if their society was engireered this in mind (and in you can trust whoever engireered it, I'm not sure if I could trust Ra) or if it was allowed to grow organically. There's nothing bad about society growing organically but in this case you can't be sure what the end result is. I think the Virtuals probably were sentient, but in a vastly different way than humans and I can't be sure if their lives are really worthwhile so my best bet is to root for humans.
:PROPERTIES:
:Score: 3
:DateUnix: 1406236958.0
:END:


** Sweet! Another update to distract me from my slight dislike of having 15+^{+} slowly updating stories!
:PROPERTIES:
:Author: Riddle-Tom_Riddle
:Score: 4
:DateUnix: 1406185594.0
:END:

*** The trick is to keep on accumulating stories that update at different times until the combined update rate matches your consumption rate.
:PROPERTIES:
:Author: drageuth2
:Score: 6
:DateUnix: 1406202264.0
:END:

**** The trick is to keep a spreadsheet of all the things you read and when they update, so you don't waste time trying to figure out what it was again that updates today.

Or go into a coma for a year. Then binge all the tasty stories... mmmm.
:PROPERTIES:
:Author: gabbalis
:Score: 2
:DateUnix: 1406211322.0
:END:

***** I usually just do a combination of RSS feeds (via feedly) and updates that go to my inbox. With those two together, I don't need to worry about actively checking for updates - the updates come to me.
:PROPERTIES:
:Author: alexanderwales
:Score: 5
:DateUnix: 1406211846.0
:END:


***** Bah, spreadsheets are too much thinking. Make an automated program to inform you that "NOW IS THE TIME TO READ X"

With enough refinement, it could even hook into RSS feeds in order to account for schedule delays. And make a genetic algorithm to figure out your story preferences and a web-spider to start finding new stories.... hmm
:PROPERTIES:
:Author: drageuth2
:Score: 1
:DateUnix: 1406213855.0
:END:
