#+TITLE: This article is about the standard test brain image. For the original human, see Miguel Acevedo.

* This article is about the standard test brain image. For the original human, see Miguel Acevedo.
:PROPERTIES:
:Author: westward101
:Score: 82
:DateUnix: 1618511914.0
:END:
â€‹

An "in the style of a Wikipedia entry" piece of fiction about the first whole brain emulation. It's not mine, and it's really really good:

[[https://qntm.org/mmacevedo]]


** For more good discussion, see this post over on SSC sub:

[[https://www.reddit.com/r/slatestarcodex/comments/lqr8hu/fiction_mmacevedo_the_brain_image_of_the_first/gue7rr8/?context=3]]
:PROPERTIES:
:Author: SvalbardCaretaker
:Score: 11
:DateUnix: 1618522195.0
:END:


** If uploading and downloading human brains becomes possible in the next few decades, I'm going to see about getting a copy of [[/u/DataPacRat]] because of [[https://docs.google.com/document/d/1nRSRWbAqtC48rPv5NG6kzggL3HXSJ1O93jFn3fgu0Rs/edit][LoadBear's Instrument of Precommitment]].

(Datapacrat, if an instance of you wakes up in the future and is tasked to write recursively derivative rational fiction, you'll have a good idea of who's manipulating your sim.)
:PROPERTIES:
:Author: GaBeRockKing
:Score: 5
:DateUnix: 1618703007.0
:END:


** This was posted 3 months ago previously:

[[https://www.reddit.com/r/rational/comments/kqugo9/rsthsfth_lena_by_sam_qntm_hughes/]]

EDIT: Why is this in negative karma? If you do not care what people had to say about the story 3 months ago, you should neither care what they have to say now. Thus you should not be voting in the comments and especially not downvoting links to previous discussion. Sheesh.
:PROPERTIES:
:Author: Dufaer
:Score: 25
:DateUnix: 1618517376.0
:END:

*** I think some people interpreted the tone of your statement as suggesting that this is a "dup", i.e. a kind of "we just talked about this" / "we don't need to see this again so soon" / "you should stop giving OP your internet points, they're just reposting things they saw yesterday" vibe. Which, coupled with the fact that the original post was from months ago, would be wrong-headed if that /was/ what you meant.

But, of course, that's /not/ what you intended to mean.

You have to be very careful with tone when making succinct Internet comments, if there's a conventional/memetic "every thread has this type of post" comment, that your comment could be misconstrued as attempting to evoke.

People like the moderators on Hacker News, the posters on [[/r/AskHistorians]], etc., try to avoid this association by phrasing the pointer to previous conversations very deferentially to the current conversation. I think the well-known format for [[/r/AskHistorians]] goes something like "There's certainly always more that can be said on this topic, but there was a previous excellent discussion [here]."
:PROPERTIES:
:Author: derefr
:Score: 22
:DateUnix: 1618522294.0
:END:


*** To be fair, you did give a [[http://www.reddit][www.reddit]] instead of old.reddit link, which, if it's not /technically/ a crime, it should be ...
:PROPERTIES:
:Author: NoYouTryAnother
:Score: 10
:DateUnix: 1618582080.0
:END:


*** Interesting points about slavery in those comments. Thanks.
:PROPERTIES:
:Author: NightmareWarden
:Score: 8
:DateUnix: 1618520541.0
:END:

**** Yeah. Is it slavery if you don't know that it's slavery and think that you have a pretty great life? I'd never really considered that before.
:PROPERTIES:
:Author: KJ6BWB
:Score: 2
:DateUnix: 1618868621.0
:END:


** After reading the story I think I am post-posthuman. I need a "do not upload" as well as a "do not resuscitate."
:PROPERTIES:
:Author: Amonwilde
:Score: 3
:DateUnix: 1618583900.0
:END:

*** Don't generalize from fictional evidence! (If you're serious).

It is a great story, but IRL, given the premises of the world, there is no way that this is economically viable. There's no way we would have brain uploading but not post human labor scarcity.
:PROPERTIES:
:Author: GreenSatyr
:Score: 6
:DateUnix: 1618608063.0
:END:

**** I've felt this way, but it seems like wishful thinking on the order of "all superintelligent AI must be ethical" to hold that no world could have uploading and want cheap minds to think about stuff
:PROPERTIES:
:Author: wren42
:Score: 4
:DateUnix: 1618610427.0
:END:

***** "All AI must be ethical" is silly, but, I still believe in the ethics of humans when collectively in an environment where all the scarcity factors that pit us against each other are gone.

But that isn't my actual objection, my actual objection is that there is no way that it turns out the /cheapest/ way to get an algorithm to do labor is to make it simulate an /entire human/, who is /unwilling/ and then /force/ it to do the labor within a simulated environment, rather than just training a specific purpose machine to do it. What task can you imagine where that is the cheapest solution? It would imply that we can't replace human general intelligence even for incredibly rote tasks that no one wants to voluntarily do but that we /can/ simulate an entire human.
:PROPERTIES:
:Author: GreenSatyr
:Score: 6
:DateUnix: 1618673270.0
:END:

****** #+begin_quote
  What task can you imagine where that is the cheapest solution?
#+end_quote

Maybe education. Imagine a whole generation taught by Severus Snapes with guns to their heads.
:PROPERTIES:
:Author: DoubleSuccessor
:Score: 3
:DateUnix: 1618707911.0
:END:


****** #+begin_quote
  But that isn't my actual objection, my actual objection is that there is no way that it turns out the cheapest way to get an algorithm to do labor is to make it simulate an entire human, who is unwilling and then force it to do the labor within a simulated environment, rather than just training a specific purpose machine to do it. What task can you imagine where that is the cheapest solution?
#+end_quote

Meanwhile in real software development, we not only don't bother optimizing our software, we go so far as to make apps in Javascript and run them in what's basically a whole web browser rather than just coding for the platform, because "developer time" is seen as so valuable and "compute" can be had in bulk. Why bother coding for a task when you could just repeatedly simulate one person known to be a good worker?
:PROPERTIES:
:Author: lucid_horizon
:Score: 2
:DateUnix: 1618803174.0
:END:


***** Not all nice things are unlikely. Theres lots of ways the future could unfold, and lots of arguments why there wouldn't be a great amount of enslaved human minds.

Wanting cheap labour doesn't mean we live in a world of ubicuous slavery, at least in the developed world so it's not a sufficient condition.

Civilization is not maximally horrible, people care about other people and treating other humans badly has other consecueces. It would be hard to have enslaved ems work on longterm wide reaching stuff for example, and if some of them manage to basically "get out of the box" you could have a movie style ai revolution only it makes more sense cause the "humans in robot suits" are actually humans.

Plus personaly I think that it would be cheaper to have non-human AI do the work.

And yeah that doesn't guarantee there won't be ems suffering despite of all that but it's certainly not obious it's going to happen or that most ems will be slaves.

And you can try to influence the future so it's less likely to be bad.
:PROPERTIES:
:Author: crivtox
:Score: 3
:DateUnix: 1618631271.0
:END:

****** Agreed it's all possible, and nice to be optimistic. I was responding to the assertion that there's "no way" ems could be used this way. Given that we have ample historical and modern examples of slavery and poor working conditions for living humans, and given that markets appear to be a pretty entrenched system, I would argue it cannot be ruled out as a possibility that emulated minds would be used for work.
:PROPERTIES:
:Author: wren42
:Score: 3
:DateUnix: 1618664557.0
:END:

******* Yes. The critique here presupposes that we would have non-emulated AI and thus be in a post-scarcity world, or that post-scarcity is a precondition for developing uploading. I think it's quite possible that rare things like cognition in general and especially cognition from individuals will continue to be valuable. I'm not saying it's the obvious or most likely future, but it's not unlikely, at least from what we know.

I honestly think optimism here is somewhat unwarranted. AI will arise in a a framework that optimizes for making money, not for well-bring. It's fine to say "advocate for the good ending," but I have no significant power to make an impact here, and others do, and are incentivized to use ems, if they are developed, to create more wealth and capital.

If faced with a coin flip between infinite heavens and infinite hells, I'd prefer to take my chances with oblivion.
:PROPERTIES:
:Author: Amonwilde
:Score: 3
:DateUnix: 1618673196.0
:END:


**** Personally, I believe, we could already be post human labor scarcity.

But we don't want to invest/research into that direction, because where else will the masses get their pay?

You could automate all jobs, minus the creative/thinking ones, but then, where will the manual laborers without those skills get a living pay?
:PROPERTIES:
:Author: TwoxMachina
:Score: 3
:DateUnix: 1618649640.0
:END:

***** Either we get universal basic income or the majority of people are going to starve.
:PROPERTIES:
:Author: LameJames1618
:Score: 3
:DateUnix: 1618659796.0
:END:


***** We are not even close, our AI can't so much as deliver a package up a flight of unfamiliar stairs yet. We /just/ got self driving cars and delivery drones for tiny packages, and i think that's pretty much the state if the art. The rich would do it if they could, paying people is expensive. It'll be at least a few decades i think, if not way more.
:PROPERTIES:
:Author: GreenSatyr
:Score: 2
:DateUnix: 1618673782.0
:END:


***** #+begin_quote
  But we don't want to invest/research into that direction, because where else will the masses get their pay?
#+end_quote

I believe that this live is already something of a simulation. It fits in with my religious beliefs. But the point of life is not to test is, it's to change us. So where does my personality need to change? How can I become a better person?

Now I've seen myself, during the pandemic or whatever, and I perhaps don't spend my spare time constructively enough. I mean, if I get a month to myself, do I blow it on 24/7 Netflix? What if I get a year? Am I really being the best me that I can be?

Now I'm nowhere near rich enough to retire. I still have 8,824 days to go. But will retiring actually be a net benefit for me or will I just become a sloth?

Now I don't want people to live on the edge, to live with food insecurity. But I do feel that some amount of work should be necessary. UBI should require at least a few hours a week or something, in my opinion. Anyway, I think we should be looking into how to reduce required hours of work but I don't want it to go down to zero as I think most people are like me and wouldn't necessarily benefit from being able to 24/7 Netflix for the rest of their lives.
:PROPERTIES:
:Author: KJ6BWB
:Score: 1
:DateUnix: 1618869679.0
:END:


** Holy shit that became horror quickly. Very well done.
:PROPERTIES:
:Author: wren42
:Score: 1
:DateUnix: 1618610247.0
:END:


** There's one realistic way to avoid this scenario. Maybe in the real world decent human brain copies will be too resource-intensive to be widespread and weak AI can take up the slack that most people would use them for. Or at least it'll remain too resource-intensive for long enough that we can get a good ethical framework to be widespread.
:PROPERTIES:
:Author: LameJames1618
:Score: 1
:DateUnix: 1618624701.0
:END:

*** Yeah, I feel like once/if we ever have the ability to simulate an entire human brain, couldn't we also modify that brain in order to fit its function? Using an entire human in order to run menial tasks seems like a waste of resources. This is entirely speculative but I feel like if we are capable of uploading consciousness we could also alter it according to its usage, removing personality, emotions, and general self-awareness. Obviously this kind of "AI-lobotomy" has its own ethical issues, but is not quite the straight-up horror that the article describes (and which has been used in /Black Mirror/ and other media as well, surely)
:PROPERTIES:
:Author: Luonnoliehre
:Score: 1
:DateUnix: 1618688329.0
:END:
